# -*- coding: utf-8 -*-
"""fetal_health_1527353.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RKfcLSdS90URlJXxPzXUYtQ3loFxWxJT

#FETAL HEALTH

#Introducción

Con esta base de datos se pretende facilitar la evaluación de feto, permitiendo así que los profesionales sean capaces de tomar las decisiones adecuadas para la salud del feto y de la madre.

El atributo mas importante que se tendrá en cuenta será fetal_health que contiene la classificación segun expertos

#inicio

Primero de todo implementamos todos los includes.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
# %matplotlib notebook
# %matplotlib inline
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as msno
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.svm import LinearSVC
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import cross_val_score
from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score
from sklearn import metrics
from sklearn.metrics import roc_curve, auc, roc_auc_score
np.random.seed(0)
def load_dataset(path):
    dataset = pd.read_csv(path, header=0, delimiter=',')
    return dataset

dataset = load_dataset('fetal_health.csv')
dataset.head()

"""Una vez cargamos los datos compruebo los 5 primeros valores para comprobar que se haya cargado.
Con esta primera información podemos ver que existen 22 columnas de atributos y algunas columnas tienen valores iguales a 0, por ahora no se puede determinar si seràn una molestia o no.
"""

dataset.info()

"""Con el dataset.info() podemos ver que la base de datos consta de 2126 entradas.
Si miramos la columna de non-Null vemos que no existen valores nulos en la base de datos y en la columna siguiente podemos ver que todos los atributos son del mismo tipo de variable (float64).
"""

dataset.isnull().sum()

"""Para asegurarme utilizo el isnull para hacer una segunda comprobación."""

dataset.describe()

"""Una vez hechado un vistazo al dataset comprobamos una primera idea de la distribución de los datos.
Podemos ver un posible desequilibrio de los datos, no obstante no podemos ver si estan normalizados o escalados, asi como la distribución de los datos, solo una aproximación.
"""

historama = dataset.hist(figsize = (20,20), color = "#FF00FF")

"""Gracias a estos gráficos podemos ver que la mayoria de atributos siguen una distribución normal a excepción de los atributos como light_decelerations."""

colours=["#FF4500","#FF0000", "#B0C4DE"]
sns.countplot(data= dataset, x="fetal_health",palette=colours)

"""Una vez realizado el gráfico podemos ver con más seguridad que los datos estan mal balanceados.
Esto puede provocar que si realizamos un estudio de accuracy no obtengamos un resultado correcto.
"""

cmap = sns.diverging_palette(205, 133, 63, as_cmap=True)
colores = (["#F0F8FF", "#0000FF", "#5F9EA0", "#FFFF00", "#ADFF2F", "#333300"])

correlacion= dataset.corr()

f, ax = plt.subplots(figsize=(15,15))
sns.heatmap(correlacion,cmap=colores,annot=True)
plt.show()

"""podemos observar que hay una alta corelación con "histogram_mode", "histogram_mean" y "histogram median" entre ello y con algunos de los otros atributos.

Si se observa la matriz de corelación podemos ver que los atributos "accelerations","prolongued_decelerations", "abnormal_short_term_variability", "percentage_of_time_with_abnormal_long_term_variability" y "mean_value_of_long_term_variability" son los que tienen mas corelación, correspondiente al color amarillo.
Tambien podemos ver que atributos tales como "histogram_number_of_zeroes", "histogram_number_of_peaks", "histogram_max" y "histogram_width" una corelación muy baja y por lo tanto no les prestaremos atención.

"""

plt.figure(figsize=(20,10))
sns.boxenplot(data = dataset,palette = colores)
plt.xticks(rotation=60)
plt.show()

"""En este gráfico podemos ver los rangos en los que se encuentran cada atributo.
Tal y como se dijo antes los valores estan muy dispersos y por lo tanto podemos ver que los rangos de los atributos son muy diferentes.
De este modo se puede ver que hay que tratar los datos antes de hacer nada mas.
Para ello  escalaré los datos.
"""

dataset_X=dataset.drop(["fetal_health"],axis=1)
dataset_Y=dataset["fetal_health"]
col = list(dataset_X.columns)
estandar_escalado = StandardScaler()
dataset_X_escalado= estandar_escalado.fit_transform(dataset_X)
dataset_X_escalado = pd.DataFrame(dataset_X_escalado, columns=col)   
dataset_X_escalado.describe()

plt.figure(figsize=(20,10))
sns.boxenplot(data = dataset_X_escalado,palette = colores)
plt.xticks(rotation=60)
plt.show()

"""Ahora podemos ver que todos los atributos se escalado correctamente y los rangos de los atributos son igualitarios, aunque hay valores que se dispersan.
Los valores que se disparan pueden ser producidos por un error de introducción o por un error humano, de este modo no los quitaremos para no perder información.

Una ver analizado los datos  y procesado los datos, se va ha proceder a realizar en entrenamiento.

Primero observare el accuracy de distintos algoritmos, he decidido utilizar:
-Regresion logística.
-Arbol de decisiones.
-Gradiente.
-Random Forest.
-KNN.
-SVC.
"""

X_train, X_test, y_train, y_test = train_test_split(dataset_X_escalado, dataset_Y,test_size=0.20, random_state=25)

pipeline_regresion_logistica = Pipeline([('lr_classifier',LogisticRegression())])

pipeline_arbol_decisiones = Pipeline([('dt_classifier',DecisionTreeClassifier())])

pipeline_gradiente = Pipeline([('gbcl_classifier',GradientBoostingClassifier())])

pipeline_arbol_aleatorio = Pipeline([('rf_classifier',RandomForestClassifier())])

pipeline_knn = Pipeline([('knn_classifier',KNeighborsClassifier())])

pipeline_svc=Pipeline([('sv_classifier',SVC())])

pipelines = [pipeline_regresion_logistica, pipeline_arbol_decisiones, pipeline_gradiente, pipeline_arbol_aleatorio, pipeline_knn, pipeline_svc]
pipe_dict = {0: 'Regresion logistica', 1: 'Arbol decisiones', 2: 'Gradiente', 3:'Arbol random', 4: 'KNN', 5: 'SVC'}

for pipe in pipelines:
    pipe.fit(X_train, y_train)

cv_results_accuracy = []
for i, model in enumerate(pipelines):
    cv_score = cross_val_score(model, X_train,y_train, cv=12)
    cv_results_accuracy.append(cv_score)
    print("%s: %f " % (pipe_dict[i], cv_score.mean()))

"""Da un warning del algoritmo de Gradient Boost, no obstante no afecta al resultado.
Tras utilizar varios algoritmos podemos ver que que el algoritmo Gradient Boost es el que tiene un valor de accuracy mas alto.
Seriá posible observar el entrenamiento con todos los algoritmos pero he tomado la decisión de utilizar solo el que tiene el valor mas alto, esto es debido a que al final el resultado seria el mismo.
"""

gradiente = GradientBoostingClassifier()
modelo = gradiente.fit(X_train, y_train)
print(f"Gradient Boosting Classifier Score: {round(modelo.score(X_test, y_test), 2)}")

prediccion = modelo.predict(X_test)

"""Una vez empezado el entrenamiento vemos que con Gradiente obtenemos un porcentaje de acierto del 96%."""

scores = cross_val_score(gradiente, X_train, y_train, cv = 8, n_jobs = 2, scoring = "accuracy")

print(f"CV scores para el modelo de Gradient Boosting Classifier :\n{scores}")
print(f"CV Mean score: {round(scores.mean(), 2)}")

"""Realizo un validación para comprobar el resultado anterior, se puede observar que el varametro de valores es próximo al obtenido y la media es muy cercano con un 95%.

Establecemos los parametros del GridSearchCV, los valores mas utilizados son los utilizados a continuacion.
"""

parametros = {"loss": ["deviance"],
              "learning_rate": [0.25, 0.5, 0.75, 1], 
              "n_estimators": [200, 350, 500, 750],
              "max_depth": [3, 6, 8]
              }

GridSearchCV_gradiente = GridSearchCV(estimator=GradientBoostingClassifier(), 
                                param_grid=parametros, 
                                cv=2,
                                verbose=1, 
                                n_jobs=-1,
                                scoring="accuracy", 
                                return_train_score=True
                                )

GridSearchCV_gradiente.fit(X_train, y_train)

mejor = GridSearchCV_gradiente.best_params_
print(f"el mejor parametro es:\n{mejor}")

"""Tras utilizar varias combinaciones podemos ver que el mejor valor de aprendizaje es un valor de 0,75, teniendo en cuenta los utilizados; con un estimadoer de 500.

Es hora de realizar un test.
"""

gradiente = GradientBoostingClassifier(criterion="friedman_mse", learning_rate=0.1, loss="deviance", 
                                  max_depth=8, max_features="log2", min_samples_leaf=0.3, 
                                  min_samples_split=0.75, n_estimators=500, random_state=25)

gradiente_mod = gradiente.fit(X_train, y_train)
pred_gbcl = gradiente_mod.predict(X_test)

score_train = gradiente_mod.score(X_train, y_train)
score_test = gradiente_mod.score(X_test, y_test)

print(f"training set = {round(score_train, 3)}")
print(f"testing set = {round(score_test, 3)}")

"""Tras realizar un entrenamiento y testeo vemos que obtenemos valores muy próximos el uno al otro, de este modo podemos suponer que funciona correctamente."""

pred = pipeline_gradiente.predict(X_test)
accuracy = accuracy_score(y_test, pred)
print(f" Testing Score es {accuracy}")
print(classification_report(y_test, pred))

"""Se obtiene un accuracy de 95,54% , el cual es muy próximo al valor de accuracy obtenido anteriormente.
Si miramos el reporte de la classificación podemos ver que hay alrededor de un 95% de posibilidades de acertar y un 96% de posibilidades de que el resultado sea correcto.
De este modo vemos que la possibilidad de acertar de forma correcta es del 95%.
"""

plt.subplots(figsize=(12,8))
matriz = confusion_matrix(y_test, pred)
sns.heatmap(matriz/np.sum(matriz), cmap='viridis',annot = True, annot_kws = {'size':20})
plt.show()

"""Si observamos la matriz de confusión podemos observar lo siguiente:
TP = 0,75
FN = 0,0141
FP = 0,0253
TN = 0,2186

#conclusiones

He podido observar que para esta base de datos el mejor algoritmo dentro de los elegidos ha sido GradientBoostingClassifier.

Teniendo en cuenta los valores obtenido y el algoritmo utilizado podemos ver que se puede obtener un resultado acertado en la mayoria de veces, de este modo es posible bajar la mortalidad infantil y las muertes durante el parto si se toman las decisiones correctas.

Tras obserbar varios ejemplos he podido observar que el procedimiento sigue la misma estructura de tratado de datos, así como las misma elecciones de entrenamiento.
"""